{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "# Instructions\n",
    "\n",
    "In this assignment, you will be working on Smile Detection using Dlib's facial landmarks model. You can [download the video from this link](https://www.dropbox.com/s/likuly4s5lz735n/smile.mp4?dl=1) and check out the video on your local system. \n",
    "\n",
    "## Task\n",
    "\n",
    "You will have to complete the `smile_detector` function. In the function, you will receive an image and you have to write the logic for smile detection and return a boolean variable indicating whether the frame has a smiling person or not. \n",
    "\n",
    "We have provided the supporting code for keeping track of the smiling frames and we will use it to compare with the ground truth. If the percentage of overlap is high enough, you will obtain full marks.\n",
    "\n",
    "Finally, we also write the output video in a avi file which you can download and see from the jupyter dashboard whether the smile is getting detected correctly.\n",
    "\n",
    "You can see the output video to check whether the code detects smile or not and help to debug your code.\n",
    "\n",
    "You will have a total of 5 attempts. This assignment carries 30 marks.\n",
    "\n",
    "Some hints:\n",
    "\n",
    "1. Find the lip and/or jaw coordinates using the facial landmarks.\n",
    "1. For a person to be smiling, the ratio of width of the lip and the jaw width should be high.\n",
    "1. Return `True` if a smile is detected, else return `False`.\n",
    "\n",
    "### Also, When you complete the assignment, you can use your own video to generate the output and share on your social media channels for fun!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "### Import Libraries and Load Dlib Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# importing the necessary packages\n",
    "import cv2\n",
    "import dlib\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# initialize dlib's face detector (HOG-based) and then create the facial landmark predictor\n",
    "print(\"[INFO] loading facial landmark predictor...\")\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "# Dlib shape predictor model path\n",
    "MODEL_PATH = \"../resource/lib/publicdata/models/shape_predictor_68_face_landmarks.dat\"\n",
    "# Load model\n",
    "shape_predictor = dlib.shape_predictor(MODEL_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "## TODO : Complete the smile detector function\n",
    "\n",
    "You need to apply the face detector and shape_predictor to the input image to get the landmarks. \n",
    "\n",
    "Then, Use the landmarks and come up with a logic so that the smile is detected for each frame.\n",
    "\n",
    "Finally, override the variable **`isSmiling`** to True if smile is detected.\n",
    "\n",
    "You can explain your logic in the next cell."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution Logic\n",
    "Write your logic here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def smile_detector(imDlib):\n",
    "    # Detect faces\n",
    "    faces = detector(imDlib, 0)\n",
    "    \n",
    "    if len(faces):\n",
    "        landmarks = shape_predictor(imDlib, faces[0])\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "    isSmiling = False\n",
    "    ###\n",
    "    left_corner = landmarks.part(47).x, landmarks.part(47).y\n",
    "    right_corner = landmarks.part(54).x, landmarks.part(54).y\n",
    "    top_lip = landmarks.part(51).y\n",
    "    bottom_lip = landmarks.part(57).y\n",
    "    lip_distance = bottom_lip - top_lip\n",
    "    mouth_distance = np.sqrt((left_corner[0] - right_corner[0])**2 + (left_corner[1] - right_corner[1])**2)\n",
    "    if lip_distance > 0.29*mouth_distance:\n",
    "        isSmiling = True\n",
    "    ###\n",
    "    # Return True if smile is detected\n",
    "    return isSmiling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main function\n",
    "\n",
    "This is the supporting function that does the video loading and saving part. \n",
    "\n",
    "It also calls the smile_detector function and keeps track of the smile_frames variable which is used in grading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Initializing video capture object.\n",
    "capture = cv2.VideoCapture(\"../resource/lib/publicdata/videos/smile.mp4\")\n",
    "if(False == capture.isOpened()):\n",
    "    print(\"[ERROR] Video not opened properly\")    \n",
    "\n",
    "# Create a VideoWriter object\n",
    "smileDetectionOut = cv2.VideoWriter(\"smileDetectionOutput.avi\",\n",
    "                                   cv2.VideoWriter_fourcc('M','J','P','G'),\n",
    "                                   15,(int(capture.get(cv2.CAP_PROP_FRAME_WIDTH)), \n",
    "                                       int(capture.get(cv2.CAP_PROP_FRAME_HEIGHT))))\n",
    "    \n",
    "frame_number = 0\n",
    "smile_frames = []\n",
    "while (True):\n",
    "    # grab the next frame\n",
    "    isGrabbed, frame = capture.read()\n",
    "    if not isGrabbed:\n",
    "        break\n",
    "        \n",
    "    imDlib = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    frame_has_smile = smile_detector(imDlib)\n",
    "    if (True == frame_has_smile):\n",
    "        cv2.putText(frame, \"Smiling :)\", (20, 80), cv2.FONT_HERSHEY_SIMPLEX, 1.0, (0, 0, 255), 2, cv2.LINE_AA)\n",
    "        smile_frames.append(frame_number)\n",
    "#         print(\"Smile detected in Frame# {}\".format(frame_number))\n",
    "    if frame_number % 50 == 0:\n",
    "        print('\\nProcessed {} frames'.format(frame_number))\n",
    "        print(\"Smile detected in Frames: {}\".format(smile_frames))\n",
    "    # Write to VideoWriter\n",
    "    smileDetectionOut.write(frame)\n",
    "    \n",
    "    frame_number += 1\n",
    "\n",
    "capture.release()\n",
    "smileDetectionOut.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "Smile Detection",
     "locked": true,
     "points": "30",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 [3.6]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
